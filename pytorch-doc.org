#+TITLE: Pytorch Documentation
#+AUTHOR: Chaitanya Kapoor


A list of important stuff in *PyTorch* that I do not want to keep using the official documentation for. I have made this using the book /"Deep Learning with PyTorch"/.

* Tensor Manipulation
Tensors are indexed similar to multidimensional arrays. A Python list can also be passed to the constructor to create a tensor.
#+begin_src python
points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])
#+end_src
The shape of the created tensor can also be accessed. Note that =shape= is *not* a callable function.
#+begin_src python
points.shape
#+end_src
Some common ways to index a tensor (analogous to lists):
#+begin_src python
points[1:]      # all rows after the first (implicitly all columns)
points[1:, :]   # all columns
points[1:, 0]   # first column
points[None]    # add a dimension of size 1 (like unsqueeze)
#+end_src

** Tensor dimensions
3D tensors have shapes in the following order:
#+begin_src python
img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]
#+end_src
A 4D image tensor has the following shape:
#+begin_src python
batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]
#+end_src
RGB dimensions are always counted third from the end, *-3*.

** In-place operations
Methods which are specific to =Tensor= objects are followed by an /underscore/. This is used to indicate that the method operates /in place/ by modifying the input instead of creating a new tensor.
#+begin_src python
a = torch.ones(3,2)
a.zero_()
#+end_src
This code block mutates =a= and returns a null tensor of shape $(3,2)$.

** Move to GPUs
A tensor can be created on the GPU by providing the following argument to the constructor:
#+begin_src python
points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')
#+end_src
We can also copy a tensor created on the CPU to the GPU with the help of the =to= method.
#+begin_src python
points_gpu = points.to(device='cuda')
#+end_src
Basic tensor operations can also be transferred to the GPU rather than performing them on the CPU.
#+begin_src python
points_gpu = 2 * points.to(device='cuda')
#+end_src

** Serializing tensors
To avoid retraining models from scratch, we can save weight tensors with the help of the =pickle= format. If we have an output file called =ourpoints.t=, then:
#+begin_src python
torch.save(points, '../ourpoints.t')
#+end_src
To load the weights, we call the =load= method.
#+begin_src python
points = torch.load('..ourpoints.t')
#+end_src

* Images
** Loading images
This can be done with the =imageio= library. Suppose that the path to the image file is ='../xyz.jpg'=:
#+begin_src python
    import imageio
    img_arr = imageio.imread('../xyz.jpg')
#+end_src
The image is loaded as a =NumPy= object. The layout of the dimensions is $H\times W\times C$ corresponding to *height*, *width* and *channel* respectively.
** Changing layout
The layout of the image tensor can be altered using the =permute= method (as expected by =Pytorch=).
#+begin_src python
 torch_img = torch.from_numpy(img_arr) # convert to torch tensor
 out = torch_img.permute(2, 0, 1) # (C X H X W)
#+end_src
An extra dimension can be added for processing batches of images by specifying the dimensions of the tensor as $N\times C\times H\times W$ where $N$ is the batch size of the images.
