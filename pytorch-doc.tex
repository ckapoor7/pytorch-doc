% Created 2022-01-06 Thu 21:01
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\author{Chaitanya Kapoor}
\date{\today}
\title{Pytorch Documentation}
\hypersetup{
 pdfauthor={Chaitanya Kapoor},
 pdftitle={Pytorch Documentation},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.5)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

A list of important stuff in \textbf{PyTorch} that I do not want to keep using the official documentation for. I have made this using the book \emph{``Deep Learning with PyTorch''}.

\section{Tensor Manipulation}
\label{sec:org6c71416}
Tensors are indexed similar to multidimensional arrays. A Python list can also be passed to the constructor to create a tensor.
\begin{minted}[]{python}
points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])
\end{minted}
The shape of the created tensor can also be accessed. Note that \texttt{shape} is \textbf{not} a callable function.
\begin{minted}[]{python}
points.shape
\end{minted}
Some common ways to index a tensor (analogous to lists):
\begin{minted}[]{python}
points[1:]      # all rows after the first (implicitly all columns)
points[1:, :]   # all columns
points[1:, 0]   # first column
points[None]    # add a dimension of size 1 (like unsqueeze)
\end{minted}

\subsection{Tensor dimensions}
\label{sec:orgec79a45}
3D tensors have shapes in the following order:
\begin{minted}[]{python}
img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]
\end{minted}
A 4D image tensor has the following shape:
\begin{minted}[]{python}
batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]
\end{minted}
RGB dimensions are always counted third from the end, \textbf{-3}.

\subsection{In-place operations}
\label{sec:orgb98b231}
Methods which are specific to \texttt{Tensor} objects are followed by an \emph{underscore}. This is used to indicate that the method operates \emph{in place} by modifying the input instead of creating a new tensor.
\begin{minted}[]{python}
a = torch.ones(3,2)
a.zero_()
\end{minted}
This code block mutates \texttt{a} and returns a null tensor of shape \((3,2)\).

\subsection{Move to GPUs}
\label{sec:org2348278}
A tensor can be created on the GPU by providing the following argument to the constructor:
\begin{minted}[]{python}
points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')
\end{minted}
We can also copy a tensor created on the CPU to the GPU with the help of the \texttt{to} method.
\begin{minted}[]{python}
points_gpu = points.to(device='cuda')
\end{minted}
Basic tensor operations can also be transferred to the GPU rather than performing them on the CPU.
\begin{minted}[]{python}
points_gpu = 2 * points.to(device='cuda')
\end{minted}

\subsection{Serializing tensors}
\label{sec:orgc517d2a}
To avoid retraining models from scratch, we can save weight tensors with the help of the \texttt{pickle} format. If we have an output file called \texttt{ourpoints.t}, then:
\begin{minted}[]{python}
torch.save(points, '../ourpoints.t')
\end{minted}
To load the weights, we call the \texttt{load} method.
\begin{minted}[]{python}
points = torch.load('..ourpoints.t')
\end{minted}

\section{Images}
\label{sec:orgdcd853e}
\subsection{Loading images}
\label{sec:org06e36e9}
This can be done with the \texttt{imageio} library. Suppose that the path to the image file is \texttt{'../xyz.jpg'}:
\begin{minted}[]{python}
    import imageio
    img_arr = imageio.imread('../xyz.jpg')
\end{minted}
The image is loaded as a \texttt{NumPy} object. The layout of the dimensions is \(H\times W\times C\) corresponding to \textbf{height}, \textbf{width} and \textbf{channel} respectively.
\subsection{Changing layout}
\label{sec:orgd635603}
The layout of the image tensor can be altered using the \texttt{permute} method (as expected by \texttt{Pytorch}).
\begin{minted}[]{python}
 torch_img = torch.from_numpy(img_arr) # convert to torch tensor
 out = torch_img.permute(2, 0, 1) # (C X H X W)
\end{minted}
An extra dimension can be added for processing batches of images by specifying the dimensions of the tensor as \(N\times C\times H\times W\) where \(N\) is the batch size of the images.
\end{document}
